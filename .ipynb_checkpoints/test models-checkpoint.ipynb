{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out model generation\n",
    "Use the cleaned out description to create n-grams/lemmatize/tfidf to get information about the features in the values\n",
    "- Use LDA or ngram frequency to get the immigration markers\n",
    "- Use collocation finder to get the years/experience markers*\n",
    "- Create a model with tfidf to see if the job provides immigration or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import job_description_features as jdf\n",
    "import job_postings as jp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>security clearance required</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we are unable to offer sponsorship</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US citizens and green card holders</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not authorized to work in the United States wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not authorized to work in the US without spons...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             phrases  Result\n",
       "0                        security clearance required   False\n",
       "1                 we are unable to offer sponsorship   False\n",
       "2                 US citizens and green card holders   False\n",
       "3  not authorized to work in the United States wi...   False\n",
       "4  not authorized to work in the US without spons...   False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_excel('Training Postings.xlsx', sheet_name='Postings')\n",
    "#data['Description']\n",
    "#data = pd.read_csv('output-today.csv')\n",
    "\n",
    "data = pd.read_excel('Training Postings.xlsx', sheet_name='Sheet1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_normalization_cleaning(text):\n",
    "    value = jdf.Description_Features(text)\n",
    "    clean_value = value.clean_description_text()\n",
    "    return clean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrases</th>\n",
       "      <th>Result</th>\n",
       "      <th>clean_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>security clearance required</td>\n",
       "      <td>False</td>\n",
       "      <td>security clearance required</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>we are unable to offer sponsorship</td>\n",
       "      <td>False</td>\n",
       "      <td>we are unable to offer sponsorship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US citizens and green card holders</td>\n",
       "      <td>False</td>\n",
       "      <td>us citizen and green card holder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not authorized to work in the United States wi...</td>\n",
       "      <td>False</td>\n",
       "      <td>not authorized to work in the united state wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not authorized to work in the US without spons...</td>\n",
       "      <td>False</td>\n",
       "      <td>not authorized to work in the us without spons...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             phrases  Result  \\\n",
       "0                        security clearance required   False   \n",
       "1                 we are unable to offer sponsorship   False   \n",
       "2                 US citizens and green card holders   False   \n",
       "3  not authorized to work in the United States wi...   False   \n",
       "4  not authorized to work in the US without spons...   False   \n",
       "\n",
       "                                          clean_desc  \n",
       "0                       security clearance required   \n",
       "1                we are unable to offer sponsorship   \n",
       "2                  us citizen and green card holder   \n",
       "3  not authorized to work in the united state wit...  \n",
       "4  not authorized to work in the us without spons...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_desc'] = data.phrases.apply(text_normalization_cleaning)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collocations\n",
    "key_phrases = ['EEO', 'visa sponsorship is available for this postion' +\n",
    "               ' is an equal opportunity employer and is committed to' + \n",
    "               'providing a work environment that is free of discrimination and harassment.' +\n",
    "               'It does not discriminate against applicants or employees with respect to any' +\n",
    "               'terms or conditions of employment on account of race, color, religion, creed,' +\n",
    "               'national origin, ancestry, sex, sexual orientation, age, genetic information,' +\n",
    "               'physical or mental disability (actual or perceived), medical condition including' + \n",
    "               'genetic characteristics, marital status, citizenship status, military service' +\n",
    "               'status, gender, gender identity, registered domestic partner status, or any other' +\n",
    "               'characteristic protected by applicable federal, state or local laws.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to try cross validation since we have a small data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Classification\n",
    "Try a classification model on the common phrases to see if it works better than clustering. When we tried clustering, the prediction was not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class Classification_Model:\n",
    "    \n",
    "    def __init__(self, X_docs, y_targets, ngrams=(1,1)):\n",
    "        self.y_names = [True, False]\n",
    "        self.y_values = y_targets\n",
    "        self.X_values = X_docs\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=ngrams,\n",
    "            max_features=1500, min_df=5, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "        self.X_vectors = self.vectorizer.fit_transform(self.X_values).toarray()\n",
    "        self.scaler = MinMaxScaler()\n",
    "        \n",
    "    def preprocessing_data(self, model):\n",
    "        #train test split\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X_vectors, self.y_values, test_size=0.20, random_state=42)\n",
    "        #scale data\n",
    "        self.scaler.fit(self.X_train)\n",
    "        self.X_train_scaled = self.scaler.transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        self.model = model\n",
    "        self.model.fit(self.X_train_scaled, self.y_train) \n",
    "        self.y_pred = self.model.predict(self.X_test_scaled)\n",
    "        \n",
    "    def model_metrics(self):\n",
    "        #confusion matrix, index = self.y_names, columns=self.y_names\n",
    "        self.conf_matrix = pd.DataFrame(confusion_matrix(self.y_test, self.y_pred))\n",
    "        #classification report with recall, precision, accuracy, target_names=self.y_names\n",
    "        print(classification_report(self.y_test, self.y_pred))\n",
    "        print('Accuracy score of ensemble classifier:', accuracy_score(self.y_test, self.y_pred))\n",
    "        return self.conf_matrix        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = Classification_Model(data.clean_desc, data.Result, ngrams=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91         5\n",
      "        True       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.92      0.75      0.79         7\n",
      "weighted avg       0.88      0.86      0.84         7\n",
      "\n",
      "Accuracy score of ensemble classifier: 0.8571428571428571\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  5  0\n",
       "1  1  1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB = GaussianNB()\n",
    "classification_model.preprocessing_data(modelNB)\n",
    "classification_model.model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91         5\n",
      "        True       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.92      0.75      0.79         7\n",
      "weighted avg       0.88      0.86      0.84         7\n",
      "\n",
      "Accuracy score of ensemble classifier: 0.8571428571428571\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  5  0\n",
       "1  1  1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier()\n",
    "classification_model.preprocessing_data(model_tree)\n",
    "classification_model.model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      1.00      0.91         5\n",
      "        True       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.86         7\n",
      "   macro avg       0.92      0.75      0.79         7\n",
      "weighted avg       0.88      0.86      0.84         7\n",
      "\n",
      "Accuracy score of ensemble classifier: 0.8571428571428571\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  5  0\n",
       "1  1  1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classification_model.preprocessing_data(model_rf)\n",
    "classification_model.model_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Latent Sentiment Analysis \n",
    "See if we can get the most common phrases and use those as a base to decide/determine job condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_ct = CountVectorizer(ngram_range=(6,6))\n",
    "data_ct = vectorizer_ct.fit_transform(data['clean_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(algorithm='randomized', n_components=2, n_iter=100,\n",
       "             random_state=None, tol=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa = TruncatedSVD(n_components=2, n_iter=100)\n",
    "lsa.fit(data_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lsa.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concept 0\n",
      "or any other characteristic protected by\n",
      "status or any other characteristic protected\n",
      "is an equal opportunity employer and\n",
      "account of race color religion creed\n",
      "actual or perceived medical condition including\n",
      "\n",
      "Concept 1\n",
      "age color national origin citizenship status\n",
      "all person regardless of age color\n",
      "and or expression genetic information marital\n",
      "any other characteristic protected by federal\n",
      "assistance veteran status or any other\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer_ct.get_feature_names()\n",
    "for i, comp in enumerate(lsa.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sortedTerms = sorted(terms_comp,key = lambda x: x[1], reverse=True) [:5] #first ten items\n",
    "    print('\\nConcept {}'.format(i))\n",
    "    for term in sortedTerms: print(term[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Clustering\n",
    "Using clustering to see if the descriptions naturally separate by the categories we want. We should try to perform clustering on n-grams instead of on unigrams\n",
    "- vectorizer_tdidf = looks for trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters /trying to see if there is an unsupervised thingy going\n",
    "from sklearn.cluster import KMeans\n",
    "class Cluster_Model:\n",
    "        \n",
    "    def __init__(self, cleaned_corpus, k_clusters = 2, ngrams=(3,3)):\n",
    "        self.corpus = cleaned_corpus\n",
    "        self.vectorizer = TfidfVectorizer(ngram_range=ngrams)\n",
    "        self.tfidf_vectors = self.vectorizer.fit_transform(self.corpus)\n",
    "        self.true_k = k_clusters\n",
    "        self.model = KMeans(n_clusters=self.true_k, init='k-means++', max_iter=100, n_init=1, n_jobs=-1)\n",
    "\n",
    "    def get_top_cluster_terms(self, n_results):\n",
    "        print(\"Top terms per cluster:\")\n",
    "        self.model.fit(self.tfidf_vectors)\n",
    "        order_centroids = self.model.cluster_centers_.argsort()[:, ::-1]\n",
    "        terms = self.vectorizer.get_feature_names()\n",
    "        for i in range(self.true_k):\n",
    "            print(\"\\nCluster {}:\".format(i)),\n",
    "            values = [terms[ind] for ind in order_centroids[i, :n_results]]\n",
    "            print(\"Terms ({}):\".format(len(values)), values)\n",
    "            #for ind in order_centroids[i, :30]:\n",
    "                #print('{}'.format(terms[ind]))\n",
    "                \n",
    "    def predict_text_cluster(self, text):\n",
    "        print(\"Prediction\")\n",
    "        Y = self.vectorizer.transform([text])\n",
    "        self.prediction = self.model.predict(Y)\n",
    "        print(self.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cluster_Model(data.clean_desc, ngrams=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0:\n",
      "Terms (10): ['this position', 'active dod', 'citizenship status', 'in the', 'regardless of', 'equal employment', 'for this', 'employment regardless', 'of citizenship', 'to work']\n",
      "\n",
      "Cluster 1:\n",
      "Terms (10): ['clearance required', 'security clearance', 'ts sci', 'us citizen', 'citizen and', 'card holder', 'and green', 'green card', 'ability to', 'and ability']\n",
      "\n",
      "Prediction\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "model.get_top_cluster_terms(10)\n",
    "print()\n",
    "model.predict_text_cluster('no sponsorship or visa at this time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA topic/feature extraction\n",
    "May help us find common traits in text so that we can classify the descriptions based on topics of interest (immigration, health industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A = list(data.desc_visa_tokens[data['desc_visa_tokens']!=''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_Topic_Model():\n",
    "    def __init__(self):\n",
    "        self.model = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('model', LatentDirichletAllocation(n_components=2, n_jobs=-1)),\n",
    "        ])\n",
    "        \n",
    "    def fit_transform(self, documents):\n",
    "        self.model.fit_transform(documents)\n",
    "        return self.model\n",
    "    \n",
    "    def get_topics(self, n = 25):\n",
    "        vectorizer = self.model.named_steps['vect']\n",
    "        model = self.model.steps[-1][1]\n",
    "        model.n_jobs = -1\n",
    "        names = vectorizer.get_feature_names()\n",
    "        topics = dict()\n",
    "        for idx, topic in enumerate(model.components_):\n",
    "            features = topic.argsort()[:-(n - 1): -1]\n",
    "            tokens = [names[i] for i in features]\n",
    "            topics[idx] = tokens\n",
    "        return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #1:\n",
      "['data', 'status', 'experience', 'work', 'equal', 'opportunity', 'protected', 'employment', 'disability', 'applicant', 'information', 'team', 'national', 'employer', 'without', 'veteran', 'business', 'must', 'origin', 'knowledge', 'race', 'orientation', 'gender']\n",
      "Topic #2:\n",
      "['job', 'business', 'science', 'experience', 'degree', 'ability', 'skill', 'practice', 'work', 'required', 'computer', 'field', 'robert', 'opening', 'half', 'authorized', 'company', 'not', 'mathematics', 'related', 'solution', 'problem', 'eligible']\n",
      "Time to process: 0:01\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "if __name__ == '__main__':\n",
    "    documents = corpus_A\n",
    "    lda = LDA_Topic_Model()\n",
    "    lda.fit_transform(documents)\n",
    "    topics = lda.get_topics()\n",
    "    for topic, terms in topics.items():\n",
    "        print(\"Topic #{}:\".format(topic+1))\n",
    "        print(terms)\n",
    "print('Time to process: {}:{:02d}'.format(round((time() - t)/60), round((time() - t)%60)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
